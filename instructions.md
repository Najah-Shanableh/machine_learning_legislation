This document outlines steps to follow to recreate building our earmark
classifier.

### Python Dependencies ###
- psycopg2
  - **Note:** In order to install psycopg2 with pip, you will also need to
    install the system packages libpq-dev and python-dev.
- beautifulsoup4
- numpy
- scipy
- mysql-connector-python
- requests
- nltk
- nose
- pandas

### Configuration ###

Create a file `earmarks.cfg` within the `conf` directory. This should be based
on the `earmarks.cfg.example` file in the directory. You need to set two values
here.

- **conn**: this is the connection string to your Postgres database
- **data** this is a file system path which will serve as the root directory
  where data such as downloaded congressional bills will be located.

### Getting the Raw Data ###

Our data source includes plain text formats for congressional bills and
congressional reports.

#### Congressional Bills ####

Bills can be downloaded from [GovTrack.us](https://www.govtrack.us/). Text
versions of bills can be downloaded via `rsync` using directions at [this
location](https://www.govtrack.us/developers/data).

#### Congressional Reports ####

Congressional reports can be downloaded using the script found at
`src/python/bill_fetcher/congress_report_downloader.py`

#### OMB Earmark Data ####

The Office of Management and Budget collected data on earmarks for the years
2005, 2008, 2009, and 2010. We use this data to create positive examples for our
earmark classifier. You can download this data using the script
`src/python/data_importer/get_omb_data.py`. This will download the CSV files and
place them in an OMB folder within the data folder set in your configuration
file.


### Creating a Database ###

To create the database tables, run the SQL script located at
`conf/create_db_tables.sql`.

#### Bills ####

To import bill data to the database, use the script
`src/python/data_importer/import_documents_to_db` passing it the `bills` argument
and the path to the bills.

Example: `python import_documents_to_db.py --bills --path
/mnt/data/sunlight/bills/110/bills/`

#### Reports ####

To import report data to the database, use the script
`src/python/data_importer/import_documents_to_db` passing it the `reports` argument
and the path to the reports.

Example: `python import_documents_to_db.py --reports --path /mnt/data/sunlight/congress_reports/111/`


#### OMB Earmarks ####

To import the table of OMB earmarks, use the script
`src/python/data_importer/load_earmarks_table.py`

#### Mapping From OMB Earmarks to Documents ####

To get a table for the mapping between earmarks and documents, use the script
`src/python/data_importer/import_omb_csv.py` passing it the path to the OMB csv
file and the year of the file.

Example: `python import_omb_csv.py --path
./2010-appropriations-earmark-extract.csv --year 2010`

#### Linking Reports and Bills ####

**TODO: This process could probably be cleaned up, and at the very least the
scripts should be cleaned up to accept parameters instead of hard coded
values.**

To link reports and bills:

1. Run the script `src/python/bill_fetcher/associate_reports_bills.py`. This
will generate a csv file linkins bill paths and report paths.
2. The script `src/python/data_importer/populate_bills_reports.py` uses the
above csv as an input and outputs another csv with linked report and bill id's.
3. This csv can be dumped into the `bill_reports` table.

###Building a Model###

#### Generating Candidate Earmarks ####
Candidate Earmarks are generated by parsing tables in congressional docuemnts
and extracting rows. To import candidates into the database, run
`src/python/util/get_entities_from_tables.py`

#### Labeling Candidtate Earmarks ####

Our goal is to create a classifier that classifies entities in tables as
earmarks or not. In order to create positive examples, we link entries from the
OMB database to table rows in documents. We also treat this as a classification
problem, first hand labeling several matches and using features of these matches
to identify the rest.

The script `src/python/matching/label_matches.py` can be used for hand labeling
pairs of OMB records and table rows as being a match or not.

To generate features for pairs of OMB records and table rows and serialize the
instances (which will later be used to build a model), use the script
`src/python/matching/prepare_matching_data` with the
serialize flag.

The `src/python/classification/diagnostics.py` script can be used with serialize a classifier trained on the matching instances

Finally, the `src/python/matching/ml_matching.py` script can be passed this
pickled classifier in order label all rows.

#### Earmark Classification ####

Now that all the rows are labeled, we can build an earmark classifier.

To generate a file of ids for  positive and negative examples, use the script
`src/python/classification/generate_training_example.py` with the positive/negative flag and the publication year of the exmaples

To generate features and serialize training instances for the examples in the files
generated above, run `src/python/classification/prepare_earmark_data.py`.

Again, the `src/python/classification/diagnostics.py` script can be used to serialize the
classifier trained on the earmark instances.


With this serialized model, you can generate a database table of earmarks for congresses the
OMB did not cover by running:
`src/python/classification/label_new_documents.py`

